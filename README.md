# Deep Research Multi-Agent System with RAG via HITL

> Multi-agent research pipeline with semantic memory, HITL curation, and LangGraph orchestration.

## Architecture

### Agent Flow

```
START
  ↓
Orchestrator — "intent == research?"
  ├── NO  → Respond to query → END
  └── YES ↓

Router — "new research or existing knowledge?"
  ├── EXISTING → Retriever (Chroma query) → Writer → END
  └── NEW ↓

Retriever (checks Chroma cache)
  ├── HIT  → Writer
  └── MISS ↓

Researcher (Tavily search + extract)
  ↓
Writer (Markdown synthesis)
  ↓
HITL — "Save to knowledge base?"
  ├── YES → Retriever (Chroma embed + store) → END
  └── NO  → END
```

### State

```
messages        → conversation history (MessagesState reducer)
intent          → "research" | "conversation"
research_mode   → "new" | "existing"
query           → research query extracted from user input
retrieved_docs  → list[Document] from Chroma (add_docs reducer)
cache_hit       → whether relevant context was found in Chroma
search_results  → list[dict] from Tavily (add_docs reducer)
final_report    → Markdown report generated by the Writer
save_to_chroma  → HITL flag for knowledge base persistence
```

### Project Structure

```
agentic-deep-research/
├── src/
│   ├── utils/
│   │   ├── state.py        → ResearchState (shared state + reducers)
│   │   ├── tools.py        → Tavily search/extract, Chroma query/save
│   │   ├── nodes.py        → orchestrator, router, retriever, researcher, writer, hitl
│   │   ├── prompts.py      → LangSmith Hub prompt retrieval
│   │   └── vectorstore.py  → Chroma singleton initialization
│   └── agent.py            → StateGraph compilation + entry point
├── langgraph.json
├── pyproject.toml
└── .env
```

## Stack

- **Orchestration**: LangGraph StateGraph
- **LLM**: GPT-5.2 Thinking
- **Search**: Tavily (search + extract)
- **Memory**: Chroma (semantic cache via HITL)
- **Observability**: LangSmith
- **Interface**: Agent Chat UI

## Setup

```bash
# Install dependencies
uv sync

# Configure environment
cp .env.example .env
# Add your API keys to .env

# Run LangGraph server
langgraph dev
```

Then open [Agent Chat UI](https://github.com/langchain-ai/agent-chat-ui) and point it to `http://localhost:2024`.